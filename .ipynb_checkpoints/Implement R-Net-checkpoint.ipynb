{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the tutorial of this link:\n",
    "http://yerevann.github.io/2017/08/25/challenges-of-reproducing-r-net-neural-network-using-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanford_corenlp_pywrapper import CoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_objects():\n",
    "    from layers import *\n",
    "    from model import *\n",
    "    return locals()\n",
    "\n",
    "def CoreNLP_path():\n",
    "    SERVER = 'http://nlp.stanford.edu/software/'\n",
    "    VERSION = 'stanford-corenlp-full-2017-06-09'\n",
    "    \n",
    "    origin = '{server}{version}.zip'.format(server= SERVER, version= VERSION)\n",
    "    lib_dir = path.join(path.abspath(path.dirname(__file__)), 'lib')\n",
    "    \n",
    "    get_file('/tmp/stanford-corenlp.zip',\n",
    "             origin=origin,\n",
    "             cache_dir=lib_dir,\n",
    "             cache_subdir='',\n",
    "             extract=True)\n",
    "\n",
    "    return path.join(lib_dir, VERSION)\n",
    "\n",
    "def get_glove_file_path():\n",
    "    SERVER = 'http://nlp.stanford.edu/data/'\n",
    "    VERSION = 'glove.840B.300d'\n",
    "\n",
    "    origin = '{server}{version}.zip'.format(server=SERVER, version=VERSION)\n",
    "    cache_dir = path.join(path.abspath(path.dirname(__file__)), 'data')\n",
    "\n",
    "    fname = '/tmp/glove.zip'\n",
    "    get_file(fname,\n",
    "             origin=origin,\n",
    "             cache_dir=cache_dir,\n",
    "             cache_subdir='',\n",
    "             extract=True)\n",
    "\n",
    "    # Remove unnecessary .zip file and keep only extracted .txt version\n",
    "    os.remove(fname)\n",
    "    return path.join(cache_dir, VERSION) + '.txt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
