{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7692, 0.5052, 0.6036],\n",
      "        [0.0760, 0.5789, 0.3462],\n",
      "        [0.7348, 0.4145, 0.5981],\n",
      "        [0.8881, 0.8629, 0.0936],\n",
      "        [0.1753, 0.4764, 0.9188]])\n"
     ]
    }
   ],
   "source": [
    "# construct a random maxtrix\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(input_size= 10,hidden_size= 20,num_layers= 2) # 10 columns input, \n",
    "                # 20 number of features in the hidden states, which mean that GRU units has 20 columns, 10 rows\n",
    "                # 2 layers means that 2 GRU stacking on the stop of each other, so 2 GRU units each 20 columns, 10 rows\n",
    "input = torch.randn(5,3,10) # 5 samples, 3 rows, 10 columns\n",
    "h0 = torch.randn(2,3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6546, -0.7034, -0.0834, -0.4357,  0.4030,  0.0287,  0.1460,\n",
      "          -0.5331, -1.1463,  0.7890],\n",
      "         [-1.5141,  1.2489, -0.4471, -1.7335, -1.3891, -0.3373,  0.9839,\n",
      "          -0.8935, -0.6172, -1.1233],\n",
      "         [ 0.7861,  1.8301, -1.0875, -1.0763,  0.8734, -0.3574,  2.4262,\n",
      "          -1.2154, -0.4193,  1.2761]],\n",
      "\n",
      "        [[-0.9014, -0.2126,  0.8084, -0.0917, -0.2006,  0.6045, -0.6600,\n",
      "          -0.2361, -0.4313, -1.9265],\n",
      "         [ 0.0477,  0.6535,  0.7252,  0.0512, -1.6827, -0.1437, -0.9672,\n",
      "           0.5336, -0.4918,  2.5779],\n",
      "         [ 0.2624,  0.5041,  1.9770, -0.9947,  0.1077,  0.0459,  0.3251,\n",
      "           1.0831,  0.6770,  0.2227]],\n",
      "\n",
      "        [[ 0.4865,  0.3402,  0.2934, -0.2328, -1.2405, -1.2117,  0.6023,\n",
      "          -0.4062, -0.3567, -1.2024],\n",
      "         [ 1.2384, -1.5203,  0.8685, -0.2750, -0.0940,  0.9869, -0.7215,\n",
      "           0.9894,  0.0644,  0.4780],\n",
      "         [ 0.0813,  1.3853,  1.0293, -0.6814, -2.2849,  0.6050,  0.5958,\n",
      "           0.3504, -0.7134,  0.0499]],\n",
      "\n",
      "        [[ 1.1476, -0.6302,  0.4845, -0.1597,  0.9275,  1.0993, -1.3599,\n",
      "           1.4499, -0.9477, -2.4179],\n",
      "         [-0.0660, -0.3274,  0.3150, -1.0368, -2.0223,  1.7914,  1.0126,\n",
      "          -0.0663,  0.1174,  0.1809],\n",
      "         [-1.9861,  0.7710,  0.8882, -0.1479,  0.4038, -1.8200, -0.2655,\n",
      "          -0.2913, -0.5959, -0.9296]],\n",
      "\n",
      "        [[-1.2837, -0.5888, -2.1139, -0.1036, -1.6901,  0.4122,  0.3719,\n",
      "           0.1522,  0.8491, -0.4436],\n",
      "         [-1.1351,  0.9370,  0.5346, -0.1839,  0.6221, -0.8675,  1.4925,\n",
      "          -0.5832,  1.8100,  0.0837],\n",
      "         [ 1.2483,  0.9990,  0.3257, -0.5986, -0.3933, -0.9004,  0.1597,\n",
      "           0.8849, -1.0511, -0.0254]]])\n",
      "==================\n",
      "tensor([[[-0.5524, -0.3422,  0.3879, -0.8576,  0.1696,  1.7379,  0.9243,\n",
      "          -0.4379, -1.4197,  1.2262,  2.2423,  0.7792, -0.1036, -0.5028,\n",
      "          -0.5386, -0.1767, -1.1227, -0.8924, -0.6254,  0.5795],\n",
      "         [-1.7269,  0.1093,  0.2390,  0.1630, -0.0767,  0.5942,  0.3448,\n",
      "           0.3933,  0.2508, -0.1391, -1.9536, -0.6107, -0.1452,  0.5266,\n",
      "           1.0084,  0.0822, -0.7660, -1.2008,  0.4570, -0.3494],\n",
      "         [ 0.7385,  1.3949, -1.2073, -1.0941, -0.6322,  1.5653,  0.1281,\n",
      "          -0.2000, -0.5258,  2.6289,  1.1184,  0.1952, -0.2163,  0.9181,\n",
      "           0.6026, -0.1829,  1.9890,  0.9453,  0.6782,  0.5373]],\n",
      "\n",
      "        [[-0.0374,  0.3880,  0.0552, -0.4981, -0.1594, -1.3096,  1.4327,\n",
      "           1.0508, -0.9567, -0.9573,  2.0258,  0.0894, -1.4711, -2.6063,\n",
      "          -0.3231, -0.5233,  0.1166, -1.8824,  0.4526, -0.6773],\n",
      "         [ 0.1748,  0.1464, -0.5388,  1.8214,  0.2877, -1.7586, -2.7644,\n",
      "          -0.4546, -1.2310, -0.0608,  0.6826, -0.6970, -0.5855,  0.4183,\n",
      "          -1.4902,  0.0738, -1.4713, -0.1841, -0.6879,  0.7438],\n",
      "         [-0.6015, -0.0215, -0.4633,  0.4644,  1.1536,  0.7218, -0.7001,\n",
      "           0.4798,  1.0526, -0.3023, -0.9572,  1.4869, -0.0289, -0.7193,\n",
      "           0.9490,  0.5365,  1.9350,  0.1970, -0.8739,  1.1941]]])\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print('==================')\n",
    "print(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hn = rnn(input, h0)\n",
    "# output: tensor containing the output features h_t from the last layer of GRU\n",
    "# hn : tensor containing the hidden state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2673e-01,  1.0052e-01, -1.8598e-01, -5.8282e-02, -9.9218e-02,\n",
      "          -8.1107e-01,  8.5400e-01,  1.6805e-01, -4.2889e-01, -3.6627e-01,\n",
      "           1.2527e+00,  2.2835e-02, -6.4946e-01, -1.2832e+00, -3.6643e-01,\n",
      "          -5.2113e-01, -2.8520e-02, -7.7953e-01,  1.7450e-01, -4.7714e-01],\n",
      "         [-8.5917e-02, -1.2557e-01, -5.3153e-01,  1.1123e+00,  1.9409e-01,\n",
      "          -1.3703e+00, -1.2791e+00, -3.0865e-01, -9.9131e-01, -2.6021e-01,\n",
      "           3.0152e-01, -3.9315e-01,  7.6967e-02,  5.0323e-01, -1.2669e+00,\n",
      "           3.3649e-02, -1.0215e+00, -3.9383e-01, -4.7953e-01,  5.6187e-01],\n",
      "         [-3.2587e-01,  5.9388e-01,  6.6342e-02, -2.4639e-01,  4.4723e-01,\n",
      "           3.5413e-01, -5.6626e-01, -1.2087e-01,  6.5510e-01, -3.4411e-01,\n",
      "           8.3223e-02,  6.5353e-01, -1.8013e-01, -4.2131e-01,  8.6981e-01,\n",
      "           2.4083e-01,  1.1445e+00,  1.5593e-02, -8.2288e-01,  3.4800e-01]],\n",
      "\n",
      "        [[-2.5153e-01,  4.4396e-02, -2.4417e-01,  6.7618e-02, -5.4877e-02,\n",
      "          -5.2341e-01,  4.2174e-01, -1.0548e-01, -1.0670e-01, -2.4366e-01,\n",
      "           6.7414e-01, -3.4374e-02, -2.6014e-01, -3.9768e-01, -2.6826e-01,\n",
      "          -4.3688e-01, -1.6807e-01, -4.3110e-01,  5.9409e-02, -3.5582e-01],\n",
      "         [-1.7575e-01, -2.2347e-01, -4.5402e-01,  5.4610e-01,  3.4312e-03,\n",
      "          -1.0727e+00, -5.0761e-01, -1.7651e-01, -6.4549e-01, -2.7901e-01,\n",
      "           1.8793e-01, -1.1541e-01,  3.1327e-01,  2.7520e-01, -9.5340e-01,\n",
      "           3.3597e-02, -7.8504e-01, -4.1889e-01, -1.7828e-01,  3.2872e-01],\n",
      "         [-2.5846e-01,  6.3556e-01,  4.5854e-02, -4.4855e-01,  1.9321e-02,\n",
      "           2.1897e-01, -3.2742e-01, -2.5146e-01,  5.2820e-01, -2.8069e-01,\n",
      "           3.3690e-01,  1.8152e-01, -1.6049e-01, -2.6809e-01,  7.4981e-01,\n",
      "           1.7235e-01,  7.2261e-01, -7.4913e-02, -6.4447e-01,  1.3223e-01]],\n",
      "\n",
      "        [[-2.9125e-01,  1.0439e-01, -2.4271e-01,  3.9298e-02, -8.3895e-02,\n",
      "          -4.3888e-01,  1.6130e-01, -2.3271e-01,  6.7721e-02, -2.2121e-01,\n",
      "           3.7445e-01, -1.2688e-01, -6.4135e-02, -6.4930e-04, -9.5728e-02,\n",
      "          -2.9668e-01, -2.4113e-01, -2.9049e-01, -4.7133e-02, -2.3377e-01],\n",
      "         [-1.7890e-01, -2.2569e-01, -3.2912e-01,  1.6526e-01, -1.4317e-01,\n",
      "          -8.4079e-01, -1.7365e-01, -1.0514e-01, -3.4671e-01, -2.5971e-01,\n",
      "           2.1761e-01,  4.8692e-03,  3.1573e-01,  2.1967e-01, -6.4159e-01,\n",
      "           5.9826e-02, -5.9503e-01, -3.6100e-01,  5.1487e-02,  2.0182e-01],\n",
      "         [-2.3878e-01,  5.7172e-01,  4.1084e-02, -4.6118e-01, -1.4751e-01,\n",
      "           1.8399e-01, -1.5139e-01, -2.3481e-01,  4.4218e-01, -2.4451e-01,\n",
      "           3.2483e-01, -2.7432e-02, -8.7345e-02, -2.1494e-01,  6.5093e-01,\n",
      "           1.3583e-01,  4.1669e-01, -2.6105e-02, -4.3787e-01,  7.3068e-02]],\n",
      "\n",
      "        [[-3.3092e-01,  1.7218e-01, -1.1608e-01,  5.2482e-02, -1.4412e-01,\n",
      "          -3.8055e-01, -3.2597e-03, -3.2507e-01,  1.5440e-01, -9.4132e-02,\n",
      "           1.9824e-01, -1.9964e-01, -1.5038e-01,  2.5299e-01,  4.0579e-03,\n",
      "          -1.6469e-01, -2.4407e-01, -2.8948e-01, -3.8625e-02, -1.6954e-01],\n",
      "         [-1.5576e-01, -1.7343e-01, -2.8154e-01, -5.2143e-02, -1.7600e-01,\n",
      "          -5.6683e-01, -2.5338e-02, -3.9699e-02, -1.2005e-01, -3.1071e-01,\n",
      "           2.1216e-01,  2.9178e-02,  2.9762e-01,  1.5762e-01, -3.9454e-01,\n",
      "           8.3496e-02, -5.2300e-01, -2.4300e-01,  1.4216e-01,  8.8463e-02],\n",
      "         [-2.3237e-01,  5.3414e-01,  8.8823e-02, -3.6174e-01, -2.2857e-01,\n",
      "           1.8234e-01, -6.5548e-02, -1.9042e-01,  4.4041e-01, -1.9070e-01,\n",
      "           2.3220e-01, -1.6706e-01, -9.6844e-03, -1.9023e-01,  5.3313e-01,\n",
      "           6.7506e-02,  1.5145e-01,  2.0894e-03, -2.7102e-01, -3.5391e-02]],\n",
      "\n",
      "        [[-2.6804e-01,  2.2863e-01, -1.7156e-01, -5.1850e-02, -2.2173e-01,\n",
      "          -2.8120e-01,  5.8593e-02, -3.1362e-01,  1.2940e-01, -1.3228e-01,\n",
      "           8.8584e-02, -1.4988e-01,  1.5038e-02,  2.9450e-01,  8.8381e-02,\n",
      "          -7.6300e-02, -2.2611e-01, -2.6129e-01, -1.3530e-01, -3.6969e-02],\n",
      "         [-1.1956e-01,  2.1223e-02, -2.7442e-01, -1.5741e-01, -2.3721e-01,\n",
      "          -3.9770e-01,  3.4871e-02, -1.9385e-02,  1.4474e-02, -3.1361e-01,\n",
      "           1.8083e-01, -3.6939e-02,  3.0069e-01,  7.0298e-02, -1.6708e-01,\n",
      "           1.1198e-01, -4.8802e-01, -1.3963e-01,  7.4148e-02,  2.7348e-02],\n",
      "         [-2.7088e-01,  4.9931e-01,  9.1483e-02, -3.3456e-01, -2.2763e-01,\n",
      "           7.8734e-02, -4.1689e-02, -2.5113e-01,  3.8470e-01, -1.6881e-01,\n",
      "           2.0436e-01, -2.5155e-01, -2.8172e-02, -1.3469e-01,  4.4989e-01,\n",
      "           9.1643e-02,  2.6012e-02,  1.6822e-02, -1.6269e-01, -8.1684e-02]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.4458e-02,  3.2060e-01, -1.0255e-01, -9.8171e-02, -1.5633e-02,\n",
      "          -1.2689e-04, -2.5318e-01, -2.2790e-01,  9.2613e-03,  3.7093e-01,\n",
      "           1.4075e-01,  2.2326e-01,  2.1236e-01,  1.9505e-01,  1.4966e-01,\n",
      "           1.3891e-01, -6.5645e-02, -2.2381e-01,  8.5626e-02,  5.1352e-02],\n",
      "         [ 2.4264e-01,  4.0696e-01,  8.6578e-02, -1.4038e-01, -9.6659e-02,\n",
      "          -2.1350e-01, -5.1851e-01,  4.0267e-01,  3.0450e-01, -6.0719e-02,\n",
      "          -6.1318e-02, -2.3823e-02,  4.1023e-01,  2.3874e-01,  2.9701e-01,\n",
      "           3.6603e-01,  9.6398e-02,  2.3080e-01,  4.0518e-01, -2.3730e-01],\n",
      "         [ 3.2749e-01,  2.3202e-01, -4.9741e-01, -5.2107e-01, -4.5047e-02,\n",
      "           9.8184e-02, -2.4374e-01,  2.4008e-01,  4.3663e-01, -5.8446e-02,\n",
      "          -5.0776e-02, -1.2316e-01,  1.5456e-01, -9.1618e-02, -3.3326e-01,\n",
      "           1.0361e-01,  5.3349e-01,  1.8425e-01,  5.5749e-02,  3.1708e-01]],\n",
      "\n",
      "        [[-2.6804e-01,  2.2863e-01, -1.7156e-01, -5.1850e-02, -2.2173e-01,\n",
      "          -2.8120e-01,  5.8593e-02, -3.1362e-01,  1.2940e-01, -1.3228e-01,\n",
      "           8.8584e-02, -1.4988e-01,  1.5038e-02,  2.9450e-01,  8.8381e-02,\n",
      "          -7.6300e-02, -2.2611e-01, -2.6129e-01, -1.3530e-01, -3.6969e-02],\n",
      "         [-1.1956e-01,  2.1223e-02, -2.7442e-01, -1.5741e-01, -2.3721e-01,\n",
      "          -3.9770e-01,  3.4871e-02, -1.9385e-02,  1.4474e-02, -3.1361e-01,\n",
      "           1.8083e-01, -3.6939e-02,  3.0069e-01,  7.0298e-02, -1.6708e-01,\n",
      "           1.1198e-01, -4.8802e-01, -1.3963e-01,  7.4148e-02,  2.7348e-02],\n",
      "         [-2.7088e-01,  4.9931e-01,  9.1483e-02, -3.3456e-01, -2.2763e-01,\n",
      "           7.8734e-02, -4.1689e-02, -2.5113e-01,  3.8470e-01, -1.6881e-01,\n",
      "           2.0436e-01, -2.5155e-01, -2.8172e-02, -1.3469e-01,  4.4989e-01,\n",
      "           9.1643e-02,  2.6012e-02,  1.6822e-02, -1.6269e-01, -8.1684e-02]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
