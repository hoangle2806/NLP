{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the tutorial of this link:\n",
    "http://yerevann.github.io/2017/08/25/challenges-of-reproducing-r-net-neural-network-using-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import cPickle as pickle\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanford_corenlp_pywrapper import CoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-0ff7e69f96c4>:1: SyntaxWarning: import * only allowed at module level\n",
      "  def custom_objects():\n",
      "<ipython-input-17-0ff7e69f96c4>:1: SyntaxWarning: import * only allowed at module level\n",
      "  def custom_objects():\n"
     ]
    }
   ],
   "source": [
    "def custom_objects():\n",
    "    from layers import *\n",
    "    from model import *\n",
    "    return locals()\n",
    "\n",
    "def CoreNLP_path():\n",
    "    SERVER = 'http://nlp.stanford.edu/software/'\n",
    "    VERSION = 'stanford-corenlp-full-2017-06-09'\n",
    "    \n",
    "    origin = '{server}{version}.zip'.format(server= SERVER, version= VERSION)\n",
    "    lib_dir = path.join(path.abspath(path.dirname(__file__)), 'lib')\n",
    "    \n",
    "    get_file('/tmp/stanford-corenlp.zip',\n",
    "             origin=origin,\n",
    "             cache_dir=lib_dir,\n",
    "             cache_subdir='',\n",
    "             extract=True)\n",
    "\n",
    "    return path.join(lib_dir, VERSION)\n",
    "\n",
    "def get_glove_file_path():\n",
    "    SERVER = 'http://nlp.stanford.edu/data/'\n",
    "    VERSION = 'glove.840B.300d'\n",
    "\n",
    "    origin = '{server}{version}.zip'.format(server=SERVER, version=VERSION)\n",
    "    cache_dir = path.join(path.abspath(path.dirname(__file__)), 'data')\n",
    "\n",
    "    fname = '/tmp/glove.zip'\n",
    "    get_file(fname,\n",
    "             origin=origin,\n",
    "             cache_dir=cache_dir,\n",
    "             cache_subdir='',\n",
    "             extract=True)\n",
    "\n",
    "    # Remove unnecessary .zip file and keep only extracted .txt version\n",
    "    os.remove(fname)\n",
    "    return path.join(cache_dir, VERSION) + '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-ef1a5343006a>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-ef1a5343006a>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    print 'Done'\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def CoreNLP_tokenizer():\n",
    "    proc = CoreNLP(configdict={'annotators': 'tokenize,ssplit'},\n",
    "                  corenlp_jars= [path.join(CoreNLP_path(), '*')])\n",
    "    \n",
    "    def tokenize_context(context):\n",
    "        parsed = proc.parse_doc(context)\n",
    "        tokens = []\n",
    "        char_offsets = []\n",
    "        for sentence in parsed['sentence']:\n",
    "            tokens += sentence['tokens']\n",
    "            char_offsets += sentence['char_offsets']\n",
    "        return tokens, char_offsets\n",
    "    return tokenize_context\n",
    "\n",
    "def word2vec(word2vec_path):\n",
    "    # Download word2vec data if it's not present yet\n",
    "    if not path.exists(word2vec_path):\n",
    "        glove_file_path = get_glove_file_path()\n",
    "        print('Converting Glove to word2vec...', end='')\n",
    "        glove2word2vec(glove_file_path, word2vec_path) # convert glove to word2vec\n",
    "        os.remove(glove_file_path) # Remove glove file and keep only word2vec\n",
    "        print('Done')\n",
    "    print('Reading word2vec data...', end='')\n",
    "    model = KeyedVectors.load_word2vec_format(word2vec_path)\n",
    "    print('Done')\n",
    "    \n",
    "    def get_word_vector(word):\n",
    "        try: \n",
    "            return model[word]\n",
    "        except KeyError:\n",
    "            return np.zeros(model.vector_size)\n",
    "    \n",
    "    return get_word_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
